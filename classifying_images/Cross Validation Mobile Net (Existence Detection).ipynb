{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import csv\n",
    "from shutil import copyfile\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "\n",
    "from keras.applications import mobilenet\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras import layers, models\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from csv import reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# moving images of both classes to one folder\n",
    "# and writing the info on them to a csv file\n",
    "csv_filename = 'data/train_cv_224/training_labels.csv'\n",
    "class_label = '0'\n",
    "originDir = f'data/train_224/{class_label}'\n",
    "targetDir = 'data/train_cv_224'\n",
    "os.makedirs(targetDir, exist_ok=True)\n",
    "with open(csv_filename, 'a') as f:\n",
    "    f.write('filename label\\n')\n",
    "    for fIdx, filename in enumerate(os.listdir(originDir)):\n",
    "        newFilename = f'{class_label}_{fIdx}.jpg'\n",
    "        copyfile(originDir+'/'+filename, targetDir+'/'+newFilename)\n",
    "#         os.rename(originDir+'/'+filename, targetDir+'/'+newFilename)\n",
    "        f.write(f'{newFilename} {class_label}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_filename = 'data/train_cv_224/training_labels.csv'\n",
    "class_label = '0'\n",
    "originDir = f'data/train_224/{class_label}'\n",
    "targetDir = 'data/train_cv_224'\n",
    "\n",
    "# reading the csv file\n",
    "train_data = pd.read_csv(csv_filename, sep=' ', header=0)\n",
    "train_data = train_data[train_data.label != 'label']\n",
    "# train_data = train_data.sample(frac=1).reset_index(drop=True) # I am not sure if I need to shuffle here\n",
    "Y = train_data[['label']]\n",
    "\n",
    "# settuping the kfolds\n",
    "kf = KFold(n_splits=5, shuffle=True)\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "idg = ImageDataGenerator(preprocessing_function=mobilenet.preprocess_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size=224\n",
    "\n",
    "def create_new_model():\n",
    "    base_model = mobilenet.MobileNet(weights='imagenet', include_top=False, input_shape=(img_size, img_size, 3))\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "    x = base_model.output\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dense(1024, activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dense(512, activation='relu')(x)\n",
    "    x = layers.Dense(1, activation='sigmoid')(x)\n",
    "    model = models.Model(inputs=base_model.input, outputs=x)\n",
    "    return model\n",
    "\n",
    "early_stopping_monitor = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    min_delta=0,\n",
    "    patience=0,\n",
    "    verbose=0,\n",
    "    mode='auto',\n",
    "    baseline=None,\n",
    "    restore_best_weights=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3217 validated image filenames belonging to 2 classes.\n",
      "Found 805 validated image filenames belonging to 2 classes.\n",
      "Epoch 1/10\n",
      "100/100 [==============================] - 14s 122ms/step - loss: 0.0648 - accuracy: 0.9673 - val_loss: 0.0139 - val_accuracy: 0.9937\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 12s 119ms/step - loss: 0.0014 - accuracy: 0.9996 - val_loss: 0.0085 - val_accuracy: 0.9987\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 12s 120ms/step - loss: 0.0030 - accuracy: 0.9992 - val_loss: 0.0021 - val_accuracy: 0.9987\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 12s 115ms/step - loss: 0.0070 - accuracy: 0.9987 - val_loss: 0.0017 - val_accuracy: 0.9987\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 12s 116ms/step - loss: 3.6163e-06 - accuracy: 1.0000 - val_loss: 0.0082 - val_accuracy: 0.9975\n",
      "26/26 [==============================] - 2s 87ms/step - loss: 0.0017 - accuracy: 0.9988\n",
      "Found 3217 validated image filenames belonging to 2 classes.\n",
      "Found 805 validated image filenames belonging to 2 classes.\n",
      "Epoch 1/10\n",
      "100/100 [==============================] - 14s 124ms/step - loss: 0.0618 - accuracy: 0.9746 - val_loss: 0.0079 - val_accuracy: 0.9962\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 12s 117ms/step - loss: 2.7299e-04 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 0.9987\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 12s 117ms/step - loss: 0.0101 - accuracy: 0.9945 - val_loss: 3.0398e-04 - val_accuracy: 1.0000\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 12s 117ms/step - loss: 0.0026 - accuracy: 0.9996 - val_loss: 0.0026 - val_accuracy: 0.9987\n",
      "26/26 [==============================] - 2s 90ms/step - loss: 3.0209e-04 - accuracy: 1.0000\n",
      "Found 3218 validated image filenames belonging to 2 classes.\n",
      "Found 804 validated image filenames belonging to 2 classes.\n",
      "Epoch 1/10\n",
      "100/100 [==============================] - 14s 125ms/step - loss: 0.0510 - accuracy: 0.9856 - val_loss: 0.0557 - val_accuracy: 0.9812\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 12s 118ms/step - loss: 0.0021 - accuracy: 0.9992 - val_loss: 0.1004 - val_accuracy: 0.9762\n",
      "26/26 [==============================] - 3s 103ms/step - loss: 0.0554 - accuracy: 0.9813\n",
      "Found 3218 validated image filenames belonging to 2 classes.\n",
      "Found 804 validated image filenames belonging to 2 classes.\n",
      "Epoch 1/10\n",
      "100/100 [==============================] - 14s 123ms/step - loss: 0.0484 - accuracy: 0.9838 - val_loss: 0.1050 - val_accuracy: 0.9688\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 12s 119ms/step - loss: 0.0023 - accuracy: 0.9996 - val_loss: 0.1651 - val_accuracy: 0.9750\n",
      "26/26 [==============================] - 3s 91ms/step - loss: 0.1045 - accuracy: 0.9689\n",
      "Found 3218 validated image filenames belonging to 2 classes.\n",
      "Found 804 validated image filenames belonging to 2 classes.\n",
      "Epoch 1/10\n",
      "100/100 [==============================] - 14s 123ms/step - loss: 0.0570 - accuracy: 0.9684 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 12s 119ms/step - loss: 0.0090 - accuracy: 0.9976 - val_loss: 0.1950 - val_accuracy: 0.9600\n",
      "26/26 [==============================] - 2s 91ms/step - loss: 0.0014 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "## Cross Validation \n",
    "valid_accuracy = []\n",
    "valid_loss = []\n",
    "batch_size=32\n",
    "num_epochs=10\n",
    "num_samples = train_data.shape[0]\n",
    "\n",
    "for train_index, val_index in kf.split(np.zeros(num_samples), Y):\n",
    "    training_data = train_data.iloc[train_index]\n",
    "    validation_data = train_data.iloc[val_index]\n",
    "    \n",
    "    train_data_generator = idg.flow_from_dataframe(training_data, directory=targetDir,\n",
    "                                                  x_col=\"filename\", y_col=\"label\",\n",
    "                                                  class_mode=\"binary\", shuffle=True,\n",
    "                                                  target_size=(img_size, img_size), batch_size=batch_size)\n",
    "    valid_data_generator = idg.flow_from_dataframe(validation_data, directory=targetDir,\n",
    "                                                  x_col=\"filename\", y_col=\"label\",\n",
    "                                                  class_mode=\"binary\", shuffle=True,\n",
    "                                                  target_size=(img_size, img_size), batch_size=batch_size)\n",
    "    \n",
    "    model = create_new_model()\n",
    "    model.compile(optimizer='rmsprop', \n",
    "                  loss='binary_crossentropy', \n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    step_size = train_data_generator.n//train_data_generator.batch_size\n",
    "    step_size_valid = valid_data_generator.n//valid_data_generator.batch_size\n",
    "\n",
    "    with tf.device('/device:GPU:0'):\n",
    "        history = model.fit(train_data_generator, epochs=num_epochs, steps_per_epoch=step_size, \n",
    "                        validation_data=valid_data_generator,\n",
    "                       validation_steps=step_size_valid,\n",
    "                        callbacks=[early_stopping_monitor])\n",
    "    \n",
    "    results = model.evaluate(valid_data_generator)\n",
    "    results = dict(zip(model.metrics_names, results))\n",
    "    \n",
    "    valid_accuracy.append(results['accuracy'])\n",
    "    valid_loss.append(results['loss'])\n",
    "    \n",
    "    tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_filename = 'data/train_cv_224/training_labels_handOverFace_unique.csv'\n",
    "class_label = '0'\n",
    "targetDir = 'data/train_cv_224'\n",
    "\n",
    "# reading the csv file\n",
    "train_data = pd.read_csv(csv_filename, sep=' ', header=0)\n",
    "train_data = train_data[train_data.label != 'label']\n",
    "# train_data = train_data.sample(frac=1).reset_index(drop=True) # I am not sure if I need to shuffle here\n",
    "Y = train_data[['label']]\n",
    "\n",
    "# settuping the kfolds\n",
    "kf = KFold(n_splits=5, shuffle=True)\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'img_size' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-69b943609b51>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m                                                   \u001b[0mx_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"filename\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"label\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                                                   \u001b[0mclass_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"raw\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                                                   target_size=(img_size, img_size), batch_size=batch_size)\n\u001b[0m\u001b[1;32m     16\u001b[0m     valid_data_generator = idg.flow_from_dataframe(validation_data, directory=targetDir,\n\u001b[1;32m     17\u001b[0m                                                   \u001b[0mx_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"filename\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"label\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'img_size' is not defined"
     ]
    }
   ],
   "source": [
    "## running only one of it\n",
    "valid_accuracy = []\n",
    "valid_loss = []\n",
    "batch_size=32\n",
    "num_epochs=10\n",
    "num_samples = train_data.shape[0]\n",
    "\n",
    "for train_index, val_index in list(kf.split(np.zeros(num_samples), Y)):\n",
    "    training_data = train_data.iloc[train_index]\n",
    "    validation_data = train_data.iloc[val_index]\n",
    "    \n",
    "    train_data_generator = idg.flow_from_dataframe(training_data, directory=targetDir,\n",
    "                                                  x_col=\"filename\", y_col=\"label\",\n",
    "                                                  class_mode=\"raw\", shuffle=True,\n",
    "                                                  target_size=(img_size, img_size), batch_size=batch_size)\n",
    "    valid_data_generator = idg.flow_from_dataframe(validation_data, directory=targetDir,\n",
    "                                                  x_col=\"filename\", y_col=\"label\",\n",
    "                                                  class_mode=\"raw\", shuffle=True,\n",
    "                                                  target_size=(img_size, img_size), batch_size=batch_size)\n",
    "    \n",
    "    model = create_new_model()\n",
    "    model.compile(optimizer='rmsprop', \n",
    "                  loss='categorical_crossentropy', \n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    step_size = train_data_generator.n//train_data_generator.batch_size\n",
    "    step_size_valid = valid_data_generator.n//valid_data_generator.batch_size\n",
    "\n",
    "    with tf.device('/device:GPU:0'):\n",
    "        history = model.fit(train_data_generator, epochs=num_epochs, steps_per_epoch=step_size, \n",
    "                        validation_data=valid_data_generator,\n",
    "                       validation_steps=step_size_valid,\n",
    "                        callbacks=[])\n",
    "    \n",
    "    results = model.evaluate(valid_data_generator)\n",
    "    results = dict(zip(model.metrics_names, results))\n",
    "    \n",
    "    valid_accuracy.append(results['accuracy'])\n",
    "    valid_loss.append(results['loss'])\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
